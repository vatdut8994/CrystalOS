{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1360 768\n"
     ]
    }
   ],
   "source": [
    "from screeninfo import get_monitors\n",
    "width = get_monitors()[0].width\n",
    "height = get_monitors()[0].height\n",
    "print(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def web_scrapper(input_data_to_search):\n",
    "    source = requests.get('https://www.google.com/search?q=' + input_data_to_search).text\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "    ans = None\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "\n",
    "    for i in soup.find_all('div', class_='BNeawe s3v9rd AP7Wnd'):\n",
    "        for j in i.find_all('div', class_='BNeawe s3v9rd AP7Wnd'):\n",
    "            list2.append(j.text)\n",
    "            list1.append(str(j.text).split(' '))\n",
    "            try:\n",
    "                ans = soup.find('div', class_='BNeawe iBp4i AP7Wnd').text\n",
    "            except AttributeError:\n",
    "                if list1[-1][-1] == 'Wikipedia':\n",
    "                    ans = j.text\n",
    "\n",
    "                else:\n",
    "                    try:\n",
    "                        if \"\\n\" in list2[1]:\n",
    "                            ans = list2[0].split('\\n')[1]\n",
    "                        else:\n",
    "                            if list2[0] == 'noun\\n':\n",
    "                                ans = list2[1]\n",
    "                            elif list2[0] == 'adjective\\n':\n",
    "                                ans = list2[1]\n",
    "                            elif list2[0] == 'verb\\n':\n",
    "                                ans = list2[1]\n",
    "                            elif list2[0] == 'adverb\\n':\n",
    "                                ans = list2[1]\n",
    "                            elif list2[0] == 'preposition\\n':\n",
    "                                ans = list2[1]\n",
    "                            else:\n",
    "                                for text in range(len(list2)):\n",
    "                                    if ':' not in list2[text] and '·' not in list2[text] and '...' not in list2[text]:\n",
    "                                        ans = list2[text]\n",
    "                                    elif ':' not in list2[text] and '·' not in list2[text]:\n",
    "                                        ans = list2[text]\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "    if ans is None:\n",
    "        ans = list2[0]\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shop Target for Lamps & Lighting you will love at great low prices. Choose from contactless Same Day Delivery, Drive Up and more.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_scrapper(\"lamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "\n",
    "def web_scrapper(input_data_to_search):\n",
    "    source = requests.get('https://www.google.com/search?q=' + input_data_to_search).text\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "    part_of_speeches = ['noun', 'adjective', 'verb', 'adverb', 'pronoun', 'preposition', 'conjunction', 'interjection']\n",
    "\n",
    "    list2 = []\n",
    "\n",
    "    for i in soup.find_all('div', class_='BNeawe s3v9rd AP7Wnd'):\n",
    "        for j in i.find_all('div', class_='BNeawe s3v9rd AP7Wnd'):\n",
    "            list2.append(j.text)\n",
    "    \n",
    "    try:\n",
    "        return soup.find('div', class_='BNeawe iBp4i AP7Wnd').text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if list2[0].split()[0] in part_of_speeches:\n",
    "        return 'As a '+list2[0].split()[0]+' it means '+list2[1]\n",
    "    \n",
    "    for text in list2:\n",
    "        if text.split()[-1] == 'Wikipedia':\n",
    "            return 'According to the Wikipedia '+str('/'.join(text.split()[0:-1]).replace('/', ' '))\n",
    "    answer_types = ['You would say that ', 'That would be ', \"That's \"]\n",
    "    for i in soup.find_all('div'):\n",
    "        for j in i.find_all('div'):\n",
    "            for k in j.find_all('div'):\n",
    "                for m in k.find_all('div'):\n",
    "                    if 'MUxGbd u31kKd gsrt lyLwlc' in str(m):\n",
    "                        translation = str(m.text).replace('Translation', '').replace('Translate', '')\n",
    "    try:\n",
    "        return random.choice(answer_types) + translation\n",
    "    \n",
    "    except:\n",
    "        urls = []\n",
    "        for a in soup.find_all('a'):\n",
    "            if a.get('href')[0:15] == '/url?q=https://':\n",
    "                url = a.get('href').replace('/url?q=https://', '')\n",
    "                urls.append(url[0: url.index('&sa')])\n",
    "        \n",
    "        for u in range(len(urls)):\n",
    "            urls[u] = 'https://'+urls[u]\n",
    "        return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.cnbc.com/2021/10/16/netflixs-squid-game-success-shines-light-on-international-discounts.html',\n",
       " 'https://www.npr.org/2021/10/16/1046541725/how-to-watch-squid-game',\n",
       " 'https://www.yahoo.com/lifestyle/thriller-series-just-dethroned-squid-160500804.html',\n",
       " 'https://www.cnbc.com/2021/10/16/every-major-wall-street-analyst-on-netflixs-third-quarter-earnings.html',\n",
       " 'https://www.yahoo.com/news/squid-game-director-says-lost-163628670.html',\n",
       " 'https://www.washingtonpost.com/business/2021/10/14/dubbing-film-ai-innovations/',\n",
       " 'https://www.yahoo.com/lifestyle/squid-game-honeycomb-challenge-got-223332713.html',\n",
       " 'https://www.latimes.com/world-nation/story/2021-10-16/the-seedy-world-of-private-lending-in-squid-game-is-a-real-temptation-in-todays-south-korea',\n",
       " 'https://www.nbcnews.com/news/asian-america/one-korean-easter-egg-leaving-squid-game-fans-devastated-rcna3027',\n",
       " 'https://kotaku.com/12-things-to-check-out-after-youve-binged-squid-game-1847875371',\n",
       " 'https://www.netflix.com/title/81040344',\n",
       " 'https://www.imdb.com/title/tt10919420/',\n",
       " 'https://www.rottentomatoes.com/tv/squid_game',\n",
       " 'https://www.youtube.com/watch%3Fv%3DoqxAJKy0ii4',\n",
       " 'https://www.youtube.com/watch%3Fv%3DoqxAJKy0ii4',\n",
       " 'https://en.wikipedia.org/wiki/Squid_Game',\n",
       " 'https://en.wikipedia.org/wiki/Statues_(game)',\n",
       " 'https://en.wikipedia.org/wiki/Liar_Game',\n",
       " 'https://en.wikipedia.org/wiki/Milk_caps_(game)',\n",
       " 'https://en.wikipedia.org/wiki/HoYeon_Jung',\n",
       " 'https://www.npr.org/2021/10/16/1046541725/how-to-watch-squid-game',\n",
       " 'https://www.vulture.com/article/planet-squid-game-netflix-biggest-show.html',\n",
       " 'https://www.cnbc.com/2021/10/16/netflixs-squid-game-success-shines-light-on-international-discounts.html',\n",
       " 'https://www.imdb.com/title/tt10919420/',\n",
       " 'https://www.hollywoodreporter.com/tv/tv-news/squid-game-creator-season-2-meaning-1235030617/',\n",
       " 'https://support.google.com/websearch%3Fp%3Dws_settings_location%26hl%3Den',\n",
       " 'https://accounts.google.com/ServiceLogin%3Fcontinue%3Dhttps://www.google.com/search%253Fq%253Dsquid%252Bgame%26hl%3Den']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_scrapper('squid game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "नमस्ते\n"
     ]
    }
   ],
   "source": [
    "# MUxGbd u31kKd gsrt lyLwlc\n",
    "source = requests.get('https://www.google.com/search?q=' + 'how to say hi in hindi').text\n",
    "soup = BeautifulSoup(source, 'lxml')\n",
    "for i in soup.find_all('div'):\n",
    "    for j in i.find_all('div'):\n",
    "        for k in j.find_all('div'):\n",
    "            for m in k.find_all('div'):\n",
    "                if 'MUxGbd u31kKd gsrt lyLwlc' in str(m):\n",
    "                    tanslation = str(m.text).replace('Translation', '').replace('Translate', '')\n",
    "print(tanslation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width/4.923076923076923, height/7.714285714285714, width/5.80060422960725, height/18.0, \n"
     ]
    }
   ],
   "source": [
    "data = '390, 140, 331, 60'\n",
    "c = 0\n",
    "final = []\n",
    "final2 = ''\n",
    "for i in data.split():\n",
    "    numbers = i.replace(',', '').replace(')', '').replace('(', '')\n",
    "    if str(c/2)[-1] == '0':\n",
    "        final.append('width/'+str(1920/int(numbers)))\n",
    "    else:\n",
    "        final.append('height/'+str(1080/int(numbers)))\n",
    "    c += 1\n",
    "for j in final:\n",
    "    final2 = final2 + (j.replace(\"'\", \"\")) + \", \"\n",
    "print(final2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "data = pandas.read_pickle('face_rec')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "source\n",
    "for a in soup.find_all('a'):\n",
    "    if 'translate' in str(a).lower():\n",
    "        print(a)\n",
    "    if a.get('href')[0:15] == '/url?q=https://':\n",
    "        url = a.get('href').replace('/url?q=https://', '')\n",
    "        urls.append(url[0: url.index('&sa')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Over 60% of Indians understand and speak Hindi\n",
      " South Indians are the LEAST likely to speak and understand Hindi\n",
      " Most people in India, especially those in the tourism industry, can understand and speak English very well\n",
      " Instead, a good way to start is to memorize certain key phrases that you can practice during your trip\n",
      " It's best if you choose a few to practice during your travels\n",
      " Namaste can be used at any time of the day\n",
      " You may also hear some people say namaskar (nam-as-scar) which can be used interchangeably with namaste\n",
      " Today many young people in India will just use the English salutations and save namaste for elders or highly respected individuals\n",
      " If you master this, the locals will think you are very polite\n",
      " This sound is pronounced by starting to say the 'buh' sound and then pushing more air out to make a 'huh' sound immediately afterward\n",
      " Many people will also use namaste for this greeting\n",
      " This is a great way to greet friends, close family members, or people similar in age to you\n",
      " This word is borrowed from Urdu, Hindi's sister language, and is formal and serious-sounding\n",
      " In all stores where prices are not written on items, it is perfectly acceptable to barter and the seller will likely quote a high price initially to see if you will pay it\n",
      " But be prepared! If you ask, you are entering into a bartering session so it's a good idea to only ask the price on items you are honestly thinking of buying\n",
      " You can add kripaya to the beginning of your English sentences when asking for directions or information to sound respectful\n",
      " This phrase is taken directly from the ancient Sanskrit language and is not often used\n",
      " However, in Hindi, there is no direct translation for this English phrase\n",
      " This phrase can also be used if you need to interrupt someone or get their attention to ask a question\n",
      " Because of this, Hindi includes a lot of honorifics or titles that are used to show respect to someone based on their societal position or age\n",
      " Instead, there are a few different honorifics that can be used in different situations\n",
      " Ji can be used for people of both genders and is placed at the end of someone's name to indicate your respect for that person\n",
      " If you want to refer to someone who is older than you, you can use the terms 'auntie' or 'uncle'\n",
      " Indians will often refer to women middle-aged and older as aunties and men of the same age as uncles\n",
      " For example, in the state of Assam, most people speak Assamese and in the state of Bengal, most people speak Bengali\n",
      " Therefore, many South Indians do not speak Hindi or learn it in school\n",
      " Most travelers have few issues when communicating with English in  South India\n",
      " You can have any trip tailor made for your travel\n",
      "\n",
      "\n",
      " Not just any journey, but the unique trip with the exceptional experiences you're looking for â whether it's a family vacation, a honeymoon, or your annual break\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mainURL = urls[0]\n",
    "urlsource = requests.get('https://'+str(mainURL)).text\n",
    "urlsoup = BeautifulSoup(urlsource, 'html.parser')\n",
    "for sentence in urlsoup.find('body').text.split('.'):\n",
    "    if '\\n' not in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_62656/329645633.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconjunctions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mphraseList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mphraseList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphraseList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "phrase = 'My name is Vatsal Dutt. I am from India. I like coding, but coding is addicting and I also like chess and chess is also addicting'\n",
    "conjunctions = ['and', 'but', 'for', 'nor', 'or', 'so', 'yet',',', '.']\n",
    "phraseList = []\n",
    "phraseList.append(phrase)\n",
    "\n",
    "for word in conjunctions:\n",
    "    for i in phraseList:\n",
    "        try:\n",
    "            phraseList[phraseList.index(i)] = i.split(word)\n",
    "        except AttributeError:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/home/crystal/.vscode/extensions/ms-toolsai.jupyter-2021.9.1001312534/out/client/extension.js:52:301180)",
      "at w.execute (/home/crystal/.vscode/extensions/ms-toolsai.jupyter-2021.9.1001312534/out/client/extension.js:52:300551)",
      "at w.start (/home/crystal/.vscode/extensions/ms-toolsai.jupyter-2021.9.1001312534/out/client/extension.js:52:296215)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/crystal/.vscode/extensions/ms-toolsai.jupyter-2021.9.1001312534/out/client/extension.js:52:310950)",
      "at async t.CellExecutionQueue.start (/home/crystal/.vscode/extensions/ms-toolsai.jupyter-2021.9.1001312534/out/client/extension.js:52:310490)"
     ]
    }
   ],
   "source": [
    "phraseList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
